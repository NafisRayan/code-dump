{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2350014,"sourceType":"datasetVersion","datasetId":1418725}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport string\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom string import punctuation\npunctuation = list(punctuation)\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T07:57:34.843763Z","iopub.execute_input":"2024-07-08T07:57:34.844273Z","iopub.status.idle":"2024-07-08T07:57:37.033416Z","shell.execute_reply.started":"2024-07-08T07:57:34.844237Z","shell.execute_reply":"2024-07-08T07:57:37.032015Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:37.035639Z","iopub.execute_input":"2024-07-08T07:57:37.036085Z","iopub.status.idle":"2024-07-08T07:57:38.775730Z","shell.execute_reply.started":"2024-07-08T07:57:37.036048Z","shell.execute_reply":"2024-07-08T07:57:38.774312Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0                                           question  \\\n0                1  Well, I thought we'd start with pronunciation,...   \n1                2  Not the hacking and gagging and spitting part....   \n2                3  You're asking me out.  That's so cute. What's ...   \n3                4  No, no, it's my fault -- we didn't have a prop...   \n4                9     Gosh, if only we could find Kat a boyfriend...   \n...            ...                                                ...   \n139404      221608    Well that one. The one who keeps looking at me.   \n139405      221609  Choose your targets men. That's right Watch th...   \n139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n139407      221611                           Your orders, Mr Vereker?   \n139408      221612  I'm to take the Sikali with the main column to...   \n\n                                                   answer  \\\n0       Not the hacking and gagging and spitting part....   \n1       Okay... then how 'bout we try out some French ...   \n2                                              Forget it.   \n3                                                Cameron.   \n4                               Let me see what I can do.   \n...                                                   ...   \n139404  ft could be you flatter yourself CoghilL It's ...   \n139405  Keep steady. You're the best shots of the Twen...   \n139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n139407  I'm to take the Sikali with the main column to...   \n139408  Lord Chelmsford seems to want me to stay back ...   \n\n                                          question_as_int  \\\n0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n...                                                   ...   \n139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n\n                                            answer_as_int  question_len  \\\n0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n...                                                   ...           ...   \n139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n\n        answer_len  \n0               55  \n1               73  \n2               10  \n3                8  \n4               25  \n...            ...  \n139404          59  \n139405          85  \n139406          60  \n139407          56  \n139408          62  \n\n[139409 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_as_int</th>\n      <th>answer_as_int</th>\n      <th>question_len</th>\n      <th>answer_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>71</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n      <td>55</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n      <td>62</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n      <td>65</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n      <td>46</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>221608</td>\n      <td>Well that one. The one who keeps looking at me.</td>\n      <td>ft could be you flatter yourself CoghilL It's ...</td>\n      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n      <td>47</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>221609</td>\n      <td>Choose your targets men. That's right Watch th...</td>\n      <td>Keep steady. You're the best shots of the Twen...</td>\n      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n      <td>61</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>221610</td>\n      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n      <td>74</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>221611</td>\n      <td>Your orders, Mr Vereker?</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>24</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>221612</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>Lord Chelmsford seems to want me to stay back ...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n      <td>56</td>\n      <td>62</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:38.777315Z","iopub.execute_input":"2024-07-08T07:57:38.777692Z","iopub.status.idle":"2024-07-08T07:57:38.983035Z","shell.execute_reply.started":"2024-07-08T07:57:38.777658Z","shell.execute_reply":"2024-07-08T07:57:38.981714Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0         0\nquestion           0\nanswer             0\nquestion_as_int    0\nanswer_as_int      0\nquestion_len       0\nanswer_len         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Modify the form of some words\nreplace_list = {r\"'m\": ' am',\n                r\"'re\": ' are',\n                r\"let’s\": 'let us',\n                r\"'s\":  ' is',\n                r\"'ve\": ' have',\n                r\"can't\": 'can not',\n                r\"cannot\": 'can not',\n                r\"shan’t\": 'shall not',\n                r\"n't\": ' not',\n                r\"'d\": ' would',\n                r\"'ll\": ' will',\n                r\"'scuse\": 'excuse',\n                ',': ' ,',\n                '.': ' .',\n                '!': ' !',\n                '?': ' ?',\n                '\\s+': ' '}\ndef clean_text(text):\n    text = text.lower()\n    for s in replace_list:\n        text = text.replace(s, replace_list[s])\n    text = ' '.join(text.split())\n    return text\n# Apply the clean_text function\ndata['question'] = data['question'].apply(lambda p: clean_text(p))\ndata['answer'] = data['answer'].apply(lambda p: clean_text(p))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:38.986513Z","iopub.execute_input":"2024-07-08T07:57:38.987049Z","iopub.status.idle":"2024-07-08T07:57:41.132338Z","shell.execute_reply.started":"2024-07-08T07:57:38.987002Z","shell.execute_reply":"2024-07-08T07:57:41.131216Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_ques = data['question']\ndata_ans = data['answer']","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:41.133898Z","iopub.execute_input":"2024-07-08T07:57:41.134268Z","iopub.status.idle":"2024-07-08T07:57:41.140050Z","shell.execute_reply.started":"2024-07-08T07:57:41.134236Z","shell.execute_reply":"2024-07-08T07:57:41.138651Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:41.141633Z","iopub.execute_input":"2024-07-08T07:57:41.142074Z","iopub.status.idle":"2024-07-08T07:57:42.684341Z","shell.execute_reply.started":"2024-07-08T07:57:41.142041Z","shell.execute_reply":"2024-07-08T07:57:42.683024Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocessing_data(data):\n    #tokenization\n    data_tokens = [word_tokenize(data[i]) for i in range(len(data))]\n    \n    #remove stopwords\n    data_cleaned = []\n    for i in range(len(data_tokens)):\n        data_cleaned.append(' '.join([lemmatizer.lemmatize(word.lower(), pos=\"v\") for word in data_tokens[i] \n                             if not word.lower() in stop_words and word not in punctuation]))  \n    return data_cleaned","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:42.686469Z","iopub.execute_input":"2024-07-08T07:57:42.686871Z","iopub.status.idle":"2024-07-08T07:57:42.694984Z","shell.execute_reply.started":"2024-07-08T07:57:42.686833Z","shell.execute_reply":"2024-07-08T07:57:42.693575Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_ques = preprocessing_data(data_ques)\ndata_ans = preprocessing_data(data_ans)\n\ndata_ques = np.array(data_ques)\ndata_ans = np.array(data_ans)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:57:42.696421Z","iopub.execute_input":"2024-07-08T07:57:42.696767Z","iopub.status.idle":"2024-07-08T07:59:06.249913Z","shell.execute_reply.started":"2024-07-08T07:57:42.696736Z","shell.execute_reply":"2024-07-08T07:59:06.248287Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"zip_data =  list(zip(data_ques, data_ans))\nlines = pd.DataFrame(zip_data, columns = ['questions' , 'answers']) \nlines.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:06.251562Z","iopub.execute_input":"2024-07-08T07:59:06.251940Z","iopub.status.idle":"2024-07-08T07:59:06.513980Z","shell.execute_reply.started":"2024-07-08T07:59:06.251907Z","shell.execute_reply":"2024-07-08T07:59:06.512884Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                   questions  \\\n0  well think would start pronunciation okay   \n1                  hack gag spit part please   \n2                              ask cute name   \n3            fault -- proper introduction --   \n4              gosh could find kat boyfriend   \n\n                                        answers  \n0                     hack gag spit part please  \n1  okay 'bout try french cuisine saturday night  \n2                                        forget  \n3                                       cameron  \n4                                       let see  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>questions</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>well think would start pronunciation okay</td>\n      <td>hack gag spit part please</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hack gag spit part please</td>\n      <td>okay 'bout try french cuisine saturday night</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ask cute name</td>\n      <td>forget</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fault -- proper introduction --</td>\n      <td>cameron</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gosh could find kat boyfriend</td>\n      <td>let see</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:06.518215Z","iopub.execute_input":"2024-07-08T07:59:06.518620Z","iopub.status.idle":"2024-07-08T07:59:16.398351Z","shell.execute_reply.started":"2024-07-08T07:59:06.518587Z","shell.execute_reply":"2024-07-08T07:59:16.396663Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"questions = list()\nfor line in lines.questions:\n    questions.append(line) \n    \ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(questions) \ntokenized_questions = tokenizer.texts_to_sequences(questions) \n\nlength_list = list()\nfor token_seq in tokenized_questions:\n    length_list.append(len(token_seq))\nmax_question_length = np.array(length_list).max()\nprint( 'Input max length is {}'.format(max_question_length))\n\npadded_questions = pad_sequences(tokenized_questions ,maxlen=max_question_length, padding='post' )\nencoder_questions_data = np.array(padded_questions)\nprint( 'Encoder input data shape -> {}'.format( encoder_questions_data.shape ))\n\nquestions_word_dict = tokenizer.word_index\nnum_question_tokens = len( questions_word_dict )+1\nprint( 'Number of Input tokens = {}'.format(num_question_tokens))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:16.400039Z","iopub.execute_input":"2024-07-08T07:59:16.400877Z","iopub.status.idle":"2024-07-08T07:59:21.204533Z","shell.execute_reply.started":"2024-07-08T07:59:16.400835Z","shell.execute_reply":"2024-07-08T07:59:21.203072Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Input max length is 20\nEncoder input data shape -> (139409, 20)\nNumber of Input tokens = 25285\n","output_type":"stream"}]},{"cell_type":"code","source":"answers = list()\nfor line in lines.answers:\n    answers.append('<START> ' + line + ' <END>')  \n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts( answers ) \ntokenized_answers = tokenizer.texts_to_sequences( answers ) \n\nlength_list = list()\nfor token_seq in tokenized_answers:\n    length_list.append( len( token_seq ))\nmax_answer_length = np.array( length_list ).max()\nprint( 'Output max length is {}'.format( max_answer_length ))\n\npadded_answers = pad_sequences( tokenized_answers , maxlen=max_answer_length, padding='post' )\ndecoder_answers_data = np.array( padded_answers )\nprint( 'Decoder input data shape -> {}'.format( decoder_answers_data.shape ))\n\nanswers_word_dict = tokenizer.word_index\nnum_answer_tokens = len( answers_word_dict )+1\nprint( 'Number of Output tokens = {}'.format( num_answer_tokens))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:21.206224Z","iopub.execute_input":"2024-07-08T07:59:21.206725Z","iopub.status.idle":"2024-07-08T07:59:26.389516Z","shell.execute_reply.started":"2024-07-08T07:59:21.206654Z","shell.execute_reply":"2024-07-08T07:59:26.388111Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Output max length is 25\nDecoder input data shape -> (139409, 25)\nNumber of Output tokens = 24993\n","output_type":"stream"}]},{"cell_type":"code","source":"decoder_target_data = list()\nfor token_seq in tokenized_answers:\n    decoder_target_data.append(token_seq[1: ]) \n    \npadded_answers_lines = pad_sequences(decoder_target_data, maxlen=max_answer_length, padding='post')\ndecoder_target_data = np.array(padded_answers_lines)\nprint( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:26.390843Z","iopub.execute_input":"2024-07-08T07:59:26.391191Z","iopub.status.idle":"2024-07-08T07:59:27.535482Z","shell.execute_reply.started":"2024-07-08T07:59:26.391161Z","shell.execute_reply":"2024-07-08T07:59:27.534196Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Decoder target data shape -> (139409, 25)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nencoder_inputs = tf.keras.layers.Input(shape=( None , ))\nencoder_embedding = tf.keras.layers.Embedding( num_question_tokens, 300 , mask_zero=True ) (encoder_inputs)\nencoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.3 , \n                                                           dropout=0.5 )( encoder_embedding )\nencoder_states = [ state_h , state_c ]\n\ndecoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\ndecoder_embedding = tf.keras.layers.Embedding( num_answer_tokens, 300 , mask_zero=True) (decoder_inputs)\ndecoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.3 , \n                                    dropout=0.5)\ndecoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\ndecoder_dense = tf.keras.layers.Dense( num_answer_tokens , activation=tf.keras.activations.softmax ) \noutput = decoder_dense ( decoder_outputs )\n\nmodel = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:59:27.536833Z","iopub.execute_input":"2024-07-08T07:59:27.537199Z","iopub.status.idle":"2024-07-08T07:59:28.468428Z","shell.execute_reply.started":"2024-07-08T07:59:27.537167Z","shell.execute_reply":"2024-07-08T07:59:28.466039Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n embedding (Embedding)          (None, None, 300)    7585500     ['input_1[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, None, 300)    7497900     ['input_2[0][0]']                \n                                                                                                  \n lstm (LSTM)                    [(None, 256),        570368      ['embedding[0][0]']              \n                                 (None, 256),                                                     \n                                 (None, 256)]                                                     \n                                                                                                  \n lstm_1 (LSTM)                  [(None, None, 256),  570368      ['embedding_1[0][0]',            \n                                 (None, 256),                     'lstm[0][1]',                   \n                                 (None, 256)]                     'lstm[0][2]']                   \n                                                                                                  \n dense (Dense)                  (None, None, 24993)  6423201     ['lstm_1[0][0]']                 \n                                                                                                  \n==================================================================================================\nTotal params: 22,647,337\nTrainable params: 22,647,337\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit([encoder_questions_data , decoder_answers_data], decoder_target_data,\n          batch_size=256, epochs=200, verbose=1)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-08T07:59:28.469903Z","iopub.execute_input":"2024-07-08T07:59:28.470282Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/200\n 55/545 [==>...........................] - ETA: 43:29 - loss: 8.3138 - accuracy: 0.2346","output_type":"stream"}]},{"cell_type":"code","source":"model.save('chatbot_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_inference_models():\n    \n    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n    \n    decoder_state_input_h = tf.keras.layers.Input(shape=(None,))\n    decoder_state_input_c = tf.keras.layers.Input(shape=(None,))\n    \n    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n    \n    decoder_outputs, state_h, state_c = decoder_lstm(\n        decoder_embedding , initial_state=decoder_states_inputs)\n    decoder_states = [state_h, state_c]\n    decoder_outputs = decoder_dense(decoder_outputs)\n    decoder_model = tf.keras.models.Model(\n        [decoder_inputs] + decoder_states_inputs,\n        [decoder_outputs] + decoder_states)\n    \n    return encoder_model , decoder_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ndef str_to_tokens( sentence : str ):\n    sentence = clean_text(sentence)\n    sentence = ' '.join([lemmatizer.lemmatize(word.lower(), pos=\"v\") for word in sentence \n                             if not word.lower() in stop_words and word not in punctuation])\n    words = sentence.split()\n    tokens_list = list()\n    for word in words:\n        tokens_list.append( questions_word_dict[ word ] ) \n    return pad_sequences( [tokens_list] , maxlen=max_question_length , padding='post')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''enc_model , dec_model = make_inference_models()\nfor epoch in range(8):\n    states_values = enc_model.predict( str_to_tokens( input( 'User: ' ) ) )\n    empty_target_seq = np.zeros( ( 1 , 1 ) )\n    empty_target_seq[0, 0] = answers_word_dict['start']\n    stop_condition = False\n    decoded_translation = ''\n    while not stop_condition :\n        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n        sampled_word = None\n        for word , index in answers_word_dict.items() :\n            if sampled_word_index == index :\n                decoded_translation += ' {}'.format( word )\n                sampled_word = word\n        \n        if sampled_word == 'end' or len(decoded_translation.split()) > max_answer_length:\n            stop_condition = True\n            \n        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n        empty_target_seq[ 0 , 0 ] = sampled_word_index\n        states_values = [ h , c ] \n\n    print( \"Bot:\" +decoded_translation.replace(' end', '') )\n    print()'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''enc_model , dec_model = make_inference_models()\n\nfor _ in range(10):\n    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n    empty_target_seq = np.zeros( ( 1 , 1 ) )\n    empty_target_seq[0, 0] = tokenizer.word_index['start']\n    stop_condition = False\n    decoded_translation = ''\n    while not stop_condition :\n        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n        sampled_word = None\n        for word , index in tokenizer.word_index.items() :\n            if sampled_word_index == index :\n                decoded_translation += ' {}'.format( word )\n                sampled_word = word\n        \n        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n            stop_condition = True\n            \n        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n        empty_target_seq[ 0 , 0 ] = sampled_word_index\n        states_values = [ h , c ] \n\n    print( decoded_translation )'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}